# YOLO Multi-Process Optimization Example

This project demonstrates a multi-process optimization approach for YOLO (You Only Look Once) object detection in videos, providing a template for improving processing performance through parallelization.

## Overview

The implementation uses Python's multiprocessing module to create a pipeline that separates video processing into three stages:
1. **Frame reading**: Reads frames from the input video
2. **Object detection**: Processes frames with YOLO model in parallel
3. **Result writing**: Reassembles and writes processed frames in correct order

This design helps maximize GPU utilization and significantly accelerates video processing compared to sequential approaches.

## Key Features

- Multi-process architecture for parallel YOLO inference
- Automatic device detection (CUDA GPU preferred, falls back to CPU)
- Ordered frame reassembly for correct video output
- Configurable number of detection processes
- Progress tracking during processing

## Usage

1. Install dependencies:
```bash
pip install torch ultralytics opencv-python
```

2. Place your YOLO model in the `model/` directory

3. Run the processing script:
```python
main('input_video.mp4', 'output_video.mp4', num_processes=4)
```

## Notes

- Adjust `num_processes` based on your available CPU cores and GPU memory
- The model path and confidence threshold can be modified in the script
- Ensure CUDA is properly configured for GPU acceleration

## Contributing

This project serves as a starting point for optimization efforts. Feel free to adapt and enhance the implementation based on your specific requirements.

## License

This example code is provided for educational and reference purposes.

*PS. The author of this gitRepo is a beginner and this doc is generated by AI.*
